## Задание 3

1. Создайте таблицу с большим количеством данных:
    ```sql
    CREATE TABLE test_cluster AS 
    SELECT 
        generate_series(1,1000000) as id,
        CASE WHEN random() < 0.5 THEN 'A' ELSE 'B' END as category,
        md5(random()::text) as data;
    ```

2. Создайте индекс:
    ```sql
    CREATE INDEX test_cluster_cat_idx ON test_cluster(category);
    ```

3. Измерьте производительность до кластеризации:
    ```sql
    EXPLAIN ANALYZE
    SELECT * FROM test_cluster WHERE category = 'A';
    ```
    
    *План выполнения:*
    ```sql
    Bitmap Heap Scan on test_cluster  (cost=59.17..7696.73 rows=5000 width=68) (actual time=15.761..68.007 rows=499944 loops=1)
      Recheck Cond: (category = 'A'::text)
      Heap Blocks: exact=8334
      ->  Bitmap Index Scan on test_cluster_cat_idx  (cost=0.00..57.92 rows=5000 width=0) (actual time=14.668..14.668 rows=499944 loops=1)
            Index Cond: (category = 'A'::text)
    Planning Time: 0.689 ms
    Execution Time: 77.612 ms
    ```
    
    *Объясните результат:*

До кластеризации используется Bitmap Heap Scan с индексом.

**Ключевые моменты:**
1. **Bitmap Index Scan** использует индекс `test_cluster_cat_idx` для быстрого определения, какие строки имеют `category = 'A'`
2. **Bitmap Heap Scan** затем читает 8334 блоков данных из таблицы
3. **Найдено 499,944 строк** (~50% от 1 млн)
4. **Время выполнения:** 77.6 мс

**Почему такой план:**
- Данные с `category = 'A'` **разбросаны случайно** по всей таблице (из-за `random()` при создании)
- Индекс указывает на случайные позиции в таблице
- Чтение 8334 блоков требует **случайного доступа** к диску (медленно)

**Проблема:** При выборке 50% таблицы индекс почти бесполезен - нужно читать почти всю таблицу, но в случайном порядке.

4. Выполните кластеризацию:
    ```sql
    CLUSTER test_cluster USING test_cluster_cat_idx;
    ```
    
    *Результат:*
    ```sql
    [2025-12-19 00:46:05] workshop.public> CLUSTER test_cluster USING test_cluster_cat_idx
    [2025-12-19 00:46:05] completed in 435 ms
    ```

5. Измерьте производительность после кластеризации:
    ```sql
    EXPLAIN ANALYZE
    SELECT * FROM test_cluster WHERE category = 'A';
    ```
    
    *План выполнения:*
    ```sql
    Bitmap Heap Scan on test_cluster  (cost=5566.78..20143.28 rows=499400 width=39) (actual time=15.936..45.413 rows=499944 loops=1)
      Recheck Cond: (category = 'A'::text)
      Heap Blocks: exact=4167
      ->  Bitmap Index Scan on test_cluster_cat_idx  (cost=0.00..5441.93 rows=499400 width=0) (actual time=15.468..15.468 rows=499944 loops=1)
            Index Cond: (category = 'A'::text)
    Planning Time: 0.461 ms
    Execution Time: 55.231 ms
    ```
    
    *Объясните результат:*

**Кластеризация сработала. Запрос ускорился на 29% (55 мс вместо 78 мс).**

**Что изменилось после кластеризации:**

1. **Данные упорядочились:** Все строки с `category = 'A'` теперь лежат **в одной области** таблицы (в первых ~4000 блоках)

2. **В 2 раза меньше блоков:** 
   - До: 8334 блоков (разбросаны по всей таблице)
   - После: 4167 блоков (компактная область)

3. **Тот же план, но эффективнее:**
   - Остался Bitmap Heap Scan
   - Но теперь он читает блоки **последовательно**, а не в случайном порядке

**Почему быстрее:**
- **Меньше перемещений головки диска** (если данные на HDD)
- **Лучше использование кэша** (если данные в памяти)
- **Компактное расположение** → меньше накладных расходов

**Итог:**
Кластеризация физически сгруппировала данные по категориям, что позволило PostgreSQL читать их быстрее. **Оптимизация удалась!**

6. Сравните производительность до и после кластеризации:
    
*Сравнение:*

**Результаты:**
- **До кластеризации:** 77.6 мс, читается 8334 блока
- **После кластеризации:** 55.2 мс, читается 4167 блоков
- **Ускорение:** 29% (на 22.4 мс быстрее)

**Что изменилось:**
1. **Данные физически упорядочились** — все строки с `category='A'` теперь лежат в одной области таблицы
2. **В 2 раза меньше операций чтения** с диска
3. **Чтение стало последовательным** вместо случайного доступа

**Почему сработала оптимизация:**
До кластеризации PostgreSQL приходилось "прыгать" по всей таблице, собирая разбросанные строки с нужной категорией. После кластеризации все нужные строки лежат компактно, что уменьшает время доступа к данным.

**Ограничения кластеризации:**
- Требует блокировки таблицы на время операции (в нашем случае 435 мс)
- Порядок нарушается при последующих INSERT/UPDATE операциях
- Неэффективна для очень маленьких или очень больших выборок (близких к 100%)

**Вывод:**
Кластеризация по часто используемому полю фильтрации (`category`) дала значительное ускорение (29%) за счет улучшения физического расположения данных на диске. Оптимизация эффективна для запросов, которые выбирают существенную часть таблицы по этому полю.